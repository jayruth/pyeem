{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of loading and processing raw EEM data\n",
    "\n",
    "* Required meta data columns in CSV/excel\n",
    "* Loading EEMs\n",
    "* Process them, including blank subtraction\n",
    "* Example with different metadata and no blank subtraction or Raman normalization\n",
    "* Create function to show porcessing steps\n",
    "    - How to store the order this was conducted in?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pyeem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 - generate a pandas dataframe with the required meta data\n",
    "\n",
    "# the return of this function should be a pandas dataframe that will be saved to H5 with the EEM datasets\n",
    "# I'll make a function for importing it form the spreadsheet template I'm using,\n",
    "# but also make it work with any pandas data frame\n",
    "\n",
    "def load_eem_meta_data(excel_file = \"EEMs.xls\"):\n",
    "    \"\"\"Read EEM meta data into a pandas dataframe from excel template provided in the pyeem examples folder:\n",
    "    \n",
    "    Args:\n",
    "        excel_file (str): relative path and file name of meta data excel file\n",
    "    \n",
    "    Returns:\n",
    "        meta_data (pandas DataFrame): meta data in a pandas data frame\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    meta_data = pd.read_excel(excel_file, sheet_name='Sample', skiprows=1)\n",
    "    meta_data = meta_data.drop(columns='Index')\n",
    "    return meta_data\n",
    "\n",
    "meta_data = load_eem_meta_data('example_data\\Description_Example.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Blank</th>\n",
       "      <th>Raman_Area</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZEF0119_Cig_5ugmL</td>\n",
       "      <td>20180227</td>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>1146.3</td>\n",
       "      <td>Cigarette 5 µg/mL</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZEF0132_Diesel_5ugmL</td>\n",
       "      <td>20180227</td>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>1146.3</td>\n",
       "      <td>Diesel 5 µg/mL</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZEF00134_Wood_5ugmL</td>\n",
       "      <td>20180227</td>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>1146.3</td>\n",
       "      <td>Wood Smoke 5 µg/mL</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>20180227</td>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>1146.3</td>\n",
       "      <td>2018-01-27 Cyclohexane Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File_Name    Folder                   Blank  Raman_Area  \\\n",
       "0       ZEF0119_Cig_5ugmL  20180227  20180227_BCycHex0p5sec      1146.3   \n",
       "1    ZEF0132_Diesel_5ugmL  20180227  20180227_BCycHex0p5sec      1146.3   \n",
       "2     ZEF00134_Wood_5ugmL  20180227  20180227_BCycHex0p5sec      1146.3   \n",
       "3  20180227_BCycHex0p5sec  20180227  20180227_BCycHex0p5sec      1146.3   \n",
       "\n",
       "                           Desc    Type  \n",
       "0             Cigarette 5 µg/mL  Sample  \n",
       "1                Diesel 5 µg/mL  Sample  \n",
       "2            Wood Smoke 5 µg/mL  Sample  \n",
       "3  2018-01-27 Cyclohexane Blank   Blank  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_hdf5_database(database_name = \"EEM_data.h5\", df = meta_data):\n",
    "    \"\"\"Description:\n",
    "    \n",
    "    Args:\n",
    "        database_name (str): filename for hdf5 database\n",
    "        df (pandas DataFrame): DataFrame containing eem meta data from 'pyeem.load_eem_meta_data' \n",
    "        function or created manually - see examples for required columns \n",
    "    Returns:\n",
    "        no retun - data is saved as h5 and may be loaded using 'pyeem.load_eem_data'\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from pandas import HDFStore\n",
    "    \n",
    "    # create an hdf5 file to store EEM meta data\n",
    "    hdf = HDFStore(database_name)\n",
    "    hdf.put('meta', df, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "    return\n",
    "\n",
    "initialize_hdf5_database(database_name = \"EEM_data.h5\", df = meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection complete, final data shape (Sample x Ex x Em): (4, 250, 151)\n",
      "(4, 151) (4, 250)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to create link (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-29cb05c81efd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mmeta_data_saver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"EEM_data.h5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'example_data/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-29cb05c81efd>\u001b[0m in \u001b[0;36mmeta_data_saver\u001b[1;34m(database_name, data_dir)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m# save data into the h5 file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatabase_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mdset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Raw Data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meem_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mdset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meem_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mdset2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Excitation\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcitation_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\smoogle\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mdset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\smoogle\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, name, obj)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHLObject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m                 \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSoftLink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.link\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to create link (name already exists)"
     ]
    }
   ],
   "source": [
    "# step 3 - load raw EEMs into H5 (should be almost the same as smoogle)\n",
    "\n",
    "def meta_data_saver(database_name, data_dir):\n",
    "    \"\"\"Add eem spectra to the H5 file created with `initialize_hdf5_database`\n",
    "    Args:\n",
    "        database_name (str): filename for hdf5 database (including relative path to file)\n",
    "        data_directory (str): relative path to where data is stored\n",
    "         \n",
    "    Returns:\n",
    "        no retun - data is saved as h5 and may be loaded using 'pyeem.load_eem_data'\n",
    "    \n",
    "    \"\"\"\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "    from pandas import read_hdf\n",
    "    \n",
    "    #load EEM file names from the saved metadata as np.array\n",
    "    file_names = np.array(read_hdf(database_name, 'meta')['File_Name'])\n",
    "    folders = np.array(read_hdf(database_name, 'meta')['Folder'])\n",
    "                          \n",
    "    #initialize lists to store data\n",
    "    eem_list = []\n",
    "    names_list = []\n",
    "    excitation_list = []\n",
    "    emission_list = []\n",
    "    \n",
    "    for i, (folder, file) in enumerate(zip(folders, file_names)):\n",
    "        eem_file = str(data_dir) + str(folder) + '/' + str(file) + '.dat'\n",
    "        # first row of EEM file is excitation wavelengths, skip when reading in file\n",
    "        eem = np.genfromtxt(eem_file, delimiter = '\\t', skip_header=1)\n",
    "        # emisson wavelengths stored in first column, store then remove\n",
    "        emission = eem[:,0]\n",
    "        eem = eem[:,1:]\n",
    "        # load the excitaion wavelenths \n",
    "        excitation = np.genfromtxt(eem_file, delimiter = '\\t', skip_header=0)[0,1:]\n",
    "        eem_list.append(eem)\n",
    "        excitation_list.append(excitation)\n",
    "        emission_list.append(emission)\n",
    "    # convert data to np arrays for saving\n",
    "    eem_list = np.array(eem_list)\n",
    "    excitation_list = np.array(excitation_list)\n",
    "    emission_list = np.array(emission_list)\n",
    "    print('Data collection complete, final data shape (Sample x Ex x Em):',eem_list.shape)\n",
    "    print(excitation_list.shape, emission_list.shape)    \n",
    "\n",
    "    # save data into the h5 file\n",
    "    with h5py.File(database_name, \"a\") as f:\n",
    "        dset = f.create_dataset(\"Raw Data\", eem_list.shape, compression=\"gzip\")\n",
    "        dset[:] = eem_list\n",
    "        dset2 = f.create_dataset(\"Excitation\", excitation_list.shape, compression=\"gzip\")\n",
    "        dset2[:] = excitation_list\n",
    "        dset3 = f.create_dataset(\"Emission\", emission_list.shape, compression=\"gzip\")\n",
    "        dset3[:] = emission_list\n",
    "\n",
    "    return\n",
    "                          \n",
    "meta_data_saver(\"EEM_data.h5\", 'example_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission            \n",
      "Excitation          \n",
      "Raw Data            \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(\"EEM_Data.h5\", 'r') as f:\n",
    "    \n",
    "#     print('The following data is available in', raw_data_name+'.hdf5')\n",
    "#     print('-' * 60)\n",
    "#     print(\"Key:\".ljust(20,' ')) #,\"Shape:\".ljust(18,' '),\"Type:\".ljust(10,' '))\n",
    "#     print('-' * 60)\n",
    "    for key in f.keys():\n",
    "        data = f[key]\n",
    "        print(key.ljust(20,' '))#, str(data.shape).ljust(18,' '), str(data.dtype).ljust(10,' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 - use the data processing fucntions for all operations\n",
    "# TO DO - create some sort of log for this porcess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally - display contour plots of the processing steps \n",
    "# (for now just code this in the notebook, maybe add a finction later)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
