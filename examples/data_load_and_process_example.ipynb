{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of loading and processing raw EEM data\n",
    "\n",
    "* Required meta data columns in CSV/excel\n",
    "* Loading EEMs\n",
    "* Process them, including blank subtraction\n",
    "* Example with different metadata and no blank subtraction or Raman normalization\n",
    "* Create function to show porcessing steps\n",
    "    - How to store the order this was conducted in?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyeem version 0.1\n"
     ]
    }
   ],
   "source": [
    "import pyeem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyeem version 0.1\n"
     ]
    }
   ],
   "source": [
    "# for development - remove when example notebook is complete\n",
    "def reload_pyeem():\n",
    "    import importlib\n",
    "    importlib.reload(pyeem.data_process)\n",
    "    importlib.reload(pyeem)\n",
    "    return\n",
    "reload_pyeem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - generate a pandas dataframe with the required meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pyeem.load_eem_meta_data('example_data\\Description_Example.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The columns 'File_Name' and 'Folder' are required, they point to the data files containing the eems to be loaded.\n",
    "- 'Blank' and 'Raman_Area' are required if `pyeem.blank_subtract` and `pyeem.raman_normalize` functions will be used.\n",
    "- All other columns are optional, as many columns as needed to describe the data may be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Blank</th>\n",
       "      <th>Raman_Area</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZEF0119_Cig_5ugmL</td>\n",
       "      <td>20180227</td>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>1146.3</td>\n",
       "      <td>Cigarette 5 µg/mL</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZEF0132_Diesel_5ugmL</td>\n",
       "      <td>20180227</td>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>1146.3</td>\n",
       "      <td>Diesel 5 µg/mL</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZEF00134_Wood_5ugmL</td>\n",
       "      <td>20180227</td>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>1146.3</td>\n",
       "      <td>Wood Smoke 5 µg/mL</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>20180227</td>\n",
       "      <td>20180227_BCycHex0p5sec</td>\n",
       "      <td>1146.3</td>\n",
       "      <td>2018-01-27 Cyclohexane Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File_Name    Folder                   Blank  Raman_Area  \\\n",
       "0       ZEF0119_Cig_5ugmL  20180227  20180227_BCycHex0p5sec      1146.3   \n",
       "1    ZEF0132_Diesel_5ugmL  20180227  20180227_BCycHex0p5sec      1146.3   \n",
       "2     ZEF00134_Wood_5ugmL  20180227  20180227_BCycHex0p5sec      1146.3   \n",
       "3  20180227_BCycHex0p5sec  20180227  20180227_BCycHex0p5sec      1146.3   \n",
       "\n",
       "                           Desc    Type  \n",
       "0             Cigarette 5 µg/mL  Sample  \n",
       "1                Diesel 5 µg/mL  Sample  \n",
       "2            Wood Smoke 5 µg/mL  Sample  \n",
       "3  2018-01-27 Cyclohexane Blank   Blank  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Initialize a h5 file and save the meta data in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwriting EEM_data.h5\n"
     ]
    }
   ],
   "source": [
    "pyeem.init_h5_database(\"EEM_data.h5\", meta_data, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEM data collection complete, final data shape (Sample x Ex x Em): (4, 250, 151)\n",
      "Dataset saved: raw_eems ... Shape =  (4, 250, 151)\n",
      "Dataset saved: eems ... Shape =  (4, 250, 151)\n",
      "Dataset saved: raw_ex ... Shape =  (4, 151)\n",
      "Dataset saved: ex ... Shape =  (4, 151)\n",
      "Dataset saved: raw_em ... Shape =  (4, 250)\n",
      "Dataset saved: em ... Shape =  (4, 250)\n"
     ]
    }
   ],
   "source": [
    "pyeem.load_eems(\"EEM_data.h5\", 'example_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved: blanks_subtracted ... Shape =  (4, 250, 151)\n",
      "Updating dataset: eems\n",
      "Dataset saved: eems ... Shape =  (4, 250, 151)\n"
     ]
    }
   ],
   "source": [
    "pyeem.blank_subtract(\"EEM_data.h5\", 'example_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Scatter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating dataset: scatter_removed\n",
      "Dataset saved: scatter_removed ... Shape =  (4, 250, 151)\n",
      "Dataset saved: excised_values ... Shape =  (4, 250, 151)\n",
      "Updating dataset: eems\n",
      "Dataset saved: eems ... Shape =  (4, 250, 151)\n"
     ]
    }
   ],
   "source": [
    "pyeem.apply_cleanscan('EEM_Data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from pyeem import cleanscan\n",
    "\n",
    "def update_eem_database(database_name, data_dict):\n",
    "    \"\"\"Helper function for updating and adding EEM data to h5 file as each step of data processing is completed:\n",
    "    \n",
    "    Args:\n",
    "        database_name (str): filename and relative path for h5 database\n",
    "        data_dict (dic): dictionary containing np.arrays of data to be saved \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with h5py.File(database_name, 'a') as f:\n",
    "        for key in data_dict.keys():\n",
    "            # check for existing dataset so data can be overwritten, if dataset doesn't exist pass\n",
    "            try:\n",
    "                del f[key]\n",
    "                print('Updating dataset:', key)\n",
    "            except KeyError:\n",
    "                pass\n",
    "            dset = f.create_dataset(key, data_dict[key].shape, compression=\"gzip\")\n",
    "            dset[:] = data_dict[key]\n",
    "            print(\"Dataset saved:\", key, \"... Shape = \", data_dict[key].shape)\n",
    "    return\n",
    "\n",
    "def apply_cleanscan(database_name, tol='Default', coeff='Default'):\n",
    "    \"\"\"Apply the scatter removal function 'cleanscan' to all EEMs in the the dataset.\n",
    "     Args:\n",
    "        database_name (str): filename for hdf5 database\n",
    "        data_dir (str): relative path to where EEM data is stored\n",
    "        tol ():parameters for applying cleanscan (see pyeem.cleanscan documentation)\n",
    "        coeff ():parameters for applying cleanscan (see pyeem.cleanscan documentation)\n",
    "       \n",
    "    Returns:\n",
    "        no retun - scatter removal results are stored in h5 database under key 'scatter_removed' \n",
    "        the intermediate results showing what values were removed and replaced by interpolation \n",
    "        are saved as 'excised_values'\n",
    "    \"\"\"\n",
    "    #test if function has already run\n",
    "    with h5py.File(database_name, 'a') as f:\n",
    "        try:\n",
    "            f.create_dataset('scatter_removed', (1,1))\n",
    "        except RuntimeError:\n",
    "            raise Exception('Cleanscan function has already run on this dataset')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    #load EEMs for scatter removal\n",
    "    try:\n",
    "        with h5py.File(database_name, 'r') as f:\n",
    "            eems = f['eems'][:]\n",
    "            ex = f['ex'][:]\n",
    "            em = f['em'][:]\n",
    "        \n",
    "    except OSError:\n",
    "        raise OSError(database_name + ' not found - please run pyeem.init_h5_database first')\n",
    "        return\n",
    "    except KeyError:\n",
    "        raise KeyError('eem data not found - please run pyeem.load_eems first')\n",
    "        return\n",
    "\n",
    "    # initalize storage for final and intermediate results\n",
    "    scatter_removed = np.zeros(eems.shape)\n",
    "    excised_values = np.zeros(eems.shape)\n",
    "    print('Removing Scatter')\n",
    "    for i in tqdm(range(eems.shape[0])):\n",
    "        scatter_removed[i, :, :], excised_values[i, :, :], _ = cleanscan(ex[i], em[i], eems[i],\n",
    "                                                                                 tol, coeff)\n",
    "\n",
    "    # update the database\n",
    "    update_eem_database(database_name, {'scatter_removed': scatter_removed,\n",
    "                                   'excised_values': excised_values,\n",
    "                                   'eems': scatter_removed})\n",
    "\n",
    "    return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File(\"EEM_Data.h5\", 'r') as f:\n",
    "    \n",
    "#     print('The following data is available in', raw_data_name+'.hdf5')\n",
    "#     print('-' * 60)\n",
    "#     print(\"Key:\".ljust(20,' ')) #,\"Shape:\".ljust(18,' '),\"Type:\".ljust(10,' '))\n",
    "#     print('-' * 60)\n",
    "    for key in f.keys():\n",
    "        data = f[key]\n",
    "        print(key.ljust(20,' '))#, str(data.shape).ljust(18,' '), str(data.dtype).ljust(10,' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 - use the data processing fucntions for all operations\n",
    "# TO DO - create some sort of log for this porcess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally - display contour plots of the processing steps \n",
    "# (for now just code this in the notebook, maybe add a finction later)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
